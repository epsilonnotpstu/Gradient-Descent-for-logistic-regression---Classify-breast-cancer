{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries",
   "id": "5e741ae31fc2b3ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:03.904093Z",
     "start_time": "2025-08-16T17:03:59.081691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "be39a77a9166419b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: Load dataset",
   "id": "727968fad411fd7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:03.997797Z",
     "start_time": "2025-08-16T17:04:03.922819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    data = pd.read_csv('Breast cancer dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset file not found. Please ensure 'Breast cancer dataset.csv' is in the correct directory.\")\n",
    "    raise"
   ],
   "id": "80f7c16c2cabe01c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 3: Preprocess dataset\n",
    "# Identify numeric columns (excluding diagnosis for now)"
   ],
   "id": "d3c5764e37edf1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.400586Z",
     "start_time": "2025-08-16T17:04:04.010585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "print(\"Numeric columns:\", numeric_cols)"
   ],
   "id": "bff27d33f9d0c701",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: Index(['id', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
      "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check for missing values",
   "id": "a8415a6ac8f56c70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.611897Z",
     "start_time": "2025-08-16T17:04:04.494590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nChecking for missing values:\")\n",
    "print(data[numeric_cols].isna().sum())"
   ],
   "id": "9a8be390f223670c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values:\n",
      "id                         0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Impute missing values with median for numeric columns",
   "id": "c14572bbb3a66053"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.711591Z",
     "start_time": "2025-08-16T17:04:04.628090Z"
    }
   },
   "cell_type": "code",
   "source": "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())",
   "id": "3c9ecbe5856e548d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check for infinite values",
   "id": "673f67fb24b9be7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.753875Z",
     "start_time": "2025-08-16T17:04:04.722428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nChecking for infinite values:\")\n",
    "print(np.isinf(data[numeric_cols]).sum())\n",
    "data[numeric_cols] = data[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())"
   ],
   "id": "dcccc7112860a75f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for infinite values:\n",
      "id                         0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Verify no NaNs remain",
   "id": "2f256125203100e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.773095Z",
     "start_time": "2025-08-16T17:04:04.765416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nChecking for NaNs after imputation:\")\n",
    "print(data[numeric_cols].isna().sum())"
   ],
   "id": "c97252037f412e00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for NaNs after imputation:\n",
      "id                         0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Encode diagnosis",
   "id": "3f4288d8e95d1d4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.801645Z",
     "start_time": "2025-08-16T17:04:04.795616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'diagnosis' in data.columns:\n",
    "    data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "else:\n",
    "    print(\"Error: 'diagnosis' column not found.\")\n",
    "    raise KeyError(\"'diagnosis' column missing\")"
   ],
   "id": "96794cb513e553a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Drop id column if present"
   ],
   "id": "e25862ce04d98516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.816869Z",
     "start_time": "2025-08-16T17:04:04.810834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'id' in data.columns:\n",
    "    data = data.drop('id', axis=1)"
   ],
   "id": "def907d133639850",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Drop zero-variance features",
   "id": "893ac179b698d381"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.844956Z",
     "start_time": "2025-08-16T17:04:04.832088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zero_variance_cols = [col for col in numeric_cols if col in data.columns and data[col].var() == 0]\n",
    "print(\"\\nZero variance columns:\", zero_variance_cols)\n",
    "data = data.drop(columns=zero_variance_cols)"
   ],
   "id": "6b091a29b866bf7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zero variance columns: []\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Separate features and target",
   "id": "97d580c143b58ddc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.862735Z",
     "start_time": "2025-08-16T17:04:04.856209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data.drop('diagnosis', axis=1).values\n",
    "y = data['diagnosis'].values"
   ],
   "id": "c9ca6c6560d88c2c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Verify no NaNs in X",
   "id": "c1f811dd890a1d75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.883868Z",
     "start_time": "2025-08-16T17:04:04.878870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if np.any(np.isnan(X)):\n",
    "    print(\"Error: NaN values found in features after preprocessing.\")\n",
    "    raise ValueError(\"NaN values in X\")"
   ],
   "id": "7436d474635d11a6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Standardize features",
   "id": "675b794fa96adad7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.916884Z",
     "start_time": "2025-08-16T17:04:04.892967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "try:\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "except ValueError as e:\n",
    "    print(\"Error in standardization:\", e)\n",
    "    raise"
   ],
   "id": "ee7b83486cb85f0e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Split data",
   "id": "e59003e103e9e83c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.948682Z",
     "start_time": "2025-08-16T17:04:04.924639Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)",
   "id": "d5b0d09f138a5498",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 4 & 6: Define and implement logistic regression from scratch",
   "id": "bef66531754097ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.977598Z",
     "start_time": "2025-08-16T17:04:04.971637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_loss(X, y, w, b):\n",
    "    m = len(y)\n",
    "    z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    epsilon = 1e-15\n",
    "    loss = -np.mean(y * np.log(y_hat + epsilon) + (1 - y) * np.log(1 - y_hat + epsilon))\n",
    "    return loss\n",
    "\n",
    "def gradient_descent(X, y, w, b, learning_rate, num_iterations):\n",
    "    m = len(y)\n",
    "    loss_history = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(X, w) + b\n",
    "        y_hat = sigmoid(z)\n",
    "        dw = np.dot(X.T, (y_hat - y)) / m\n",
    "        db = np.mean(y_hat - y)\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "        loss = compute_loss(X, y, w, b)\n",
    "        loss_history.append(loss)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return w, b, loss_history\n",
    "\n",
    "def predict(X, w, b, threshold=0.5):\n",
    "    z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    return (y_hat >= threshold).astype(int)\n"
   ],
   "id": "57a97ab3f6475e60",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train custom model",
   "id": "7182b75e0d6bc4c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:04:04.989238Z",
     "start_time": "2025-08-16T17:04:04.987261Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bdb4240264e774cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
