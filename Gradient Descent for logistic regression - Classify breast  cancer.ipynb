{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries",
   "id": "5e741ae31fc2b3ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.400212Z",
     "start_time": "2025-08-16T17:38:36.396939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "be39a77a9166419b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: Load dataset",
   "id": "727968fad411fd7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.463834Z",
     "start_time": "2025-08-16T17:38:36.458787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    data = pd.read_csv('Breast cancer dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset file not found. Please ensure 'Breast cancer dataset.csv' is in the correct directory.\")\n",
    "    raise"
   ],
   "id": "80f7c16c2cabe01c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 3: Preprocess dataset\n",
    "# Identify numeric columns (excluding diagnosis for now)"
   ],
   "id": "d3c5764e37edf1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.520971Z",
     "start_time": "2025-08-16T17:38:36.517633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "print(\"Numeric columns:\", numeric_cols)"
   ],
   "id": "bff27d33f9d0c701",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: Index(['id', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
      "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check for missing values",
   "id": "a8415a6ac8f56c70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.584450Z",
     "start_time": "2025-08-16T17:38:36.579658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nChecking for missing values:\")\n",
    "print(data[numeric_cols].isna().sum())"
   ],
   "id": "9a8be390f223670c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values:\n",
      "id                         0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Impute missing values with median for numeric columns",
   "id": "c14572bbb3a66053"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.654739Z",
     "start_time": "2025-08-16T17:38:36.644370Z"
    }
   },
   "cell_type": "code",
   "source": "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())",
   "id": "3c9ecbe5856e548d",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check for infinite values",
   "id": "673f67fb24b9be7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.720062Z",
     "start_time": "2025-08-16T17:38:36.702904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nChecking for infinite values:\")\n",
    "print(np.isinf(data[numeric_cols]).sum())\n",
    "data[numeric_cols] = data[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())"
   ],
   "id": "dcccc7112860a75f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for infinite values:\n",
      "id                         0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Verify no NaNs remain",
   "id": "2f256125203100e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.768711Z",
     "start_time": "2025-08-16T17:38:36.763064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nChecking for NaNs after imputation:\")\n",
    "print(data[numeric_cols].isna().sum())"
   ],
   "id": "c97252037f412e00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for NaNs after imputation:\n",
      "id                         0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Encode diagnosis",
   "id": "3f4288d8e95d1d4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.826482Z",
     "start_time": "2025-08-16T17:38:36.823898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'diagnosis' in data.columns:\n",
    "    data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "else:\n",
    "    print(\"Error: 'diagnosis' column not found.\")\n",
    "    raise KeyError(\"'diagnosis' column missing\")"
   ],
   "id": "96794cb513e553a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Drop id column if present"
   ],
   "id": "e25862ce04d98516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.886091Z",
     "start_time": "2025-08-16T17:38:36.883631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'id' in data.columns:\n",
    "    data = data.drop('id', axis=1)"
   ],
   "id": "def907d133639850",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Drop zero-variance features",
   "id": "893ac179b698d381"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:36.946670Z",
     "start_time": "2025-08-16T17:38:36.940726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zero_variance_cols = [col for col in numeric_cols if col in data.columns and data[col].var() == 0]\n",
    "print(\"\\nZero variance columns:\", zero_variance_cols)\n",
    "data = data.drop(columns=zero_variance_cols)"
   ],
   "id": "6b091a29b866bf7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zero variance columns: []\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Separate features and target",
   "id": "97d580c143b58ddc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:37.005277Z",
     "start_time": "2025-08-16T17:38:37.002140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data.drop('diagnosis', axis=1).values\n",
    "y = data['diagnosis'].values"
   ],
   "id": "c9ca6c6560d88c2c",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Verify no NaNs in X",
   "id": "c1f811dd890a1d75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:37.062118Z",
     "start_time": "2025-08-16T17:38:37.060229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if np.any(np.isnan(X)):\n",
    "    print(\"Error: NaN values found in features after preprocessing.\")\n",
    "    raise ValueError(\"NaN values in X\")"
   ],
   "id": "7436d474635d11a6",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Standardize features",
   "id": "675b794fa96adad7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:37.119669Z",
     "start_time": "2025-08-16T17:38:37.117102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "try:\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "except ValueError as e:\n",
    "    print(\"Error in standardization:\", e)\n",
    "    raise"
   ],
   "id": "ee7b83486cb85f0e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Split data",
   "id": "e59003e103e9e83c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:37.178230Z",
     "start_time": "2025-08-16T17:38:37.175965Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)",
   "id": "d5b0d09f138a5498",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 4 & 6: Define and implement logistic regression from scratch",
   "id": "bef66531754097ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:37.241564Z",
     "start_time": "2025-08-16T17:38:37.238083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_loss(X, y, w, b):\n",
    "    m = len(y)\n",
    "    z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    epsilon = 1e-15\n",
    "    loss = -np.mean(y * np.log(y_hat + epsilon) + (1 - y) * np.log(1 - y_hat + epsilon))\n",
    "    return loss\n",
    "\n",
    "def gradient_descent(X, y, w, b, learning_rate, num_iterations):\n",
    "    m = len(y)\n",
    "    loss_history = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(X, w) + b\n",
    "        y_hat = sigmoid(z)\n",
    "        dw = np.dot(X.T, (y_hat - y)) / m\n",
    "        db = np.mean(y_hat - y)\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "        loss = compute_loss(X, y, w, b)\n",
    "        loss_history.append(loss)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return w, b, loss_history\n",
    "\n",
    "def predict(X, w, b, threshold=0.5):\n",
    "    z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    return (y_hat >= threshold).astype(int)\n"
   ],
   "id": "57a97ab3f6475e60",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train custom model",
   "id": "7182b75e0d6bc4c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:37.344196Z",
     "start_time": "2025-08-16T17:38:37.292973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "w = np.random.randn(X_train.shape[1])\n",
    "b = 0\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "w, b, loss_history = gradient_descent(X_train, y_train, w, b, learning_rate, num_iterations)"
   ],
   "id": "bdb4240264e774cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.7447\n",
      "Iteration 100, Loss: 0.5733\n",
      "Iteration 200, Loss: 0.3398\n",
      "Iteration 300, Loss: 0.2654\n",
      "Iteration 400, Loss: 0.2268\n",
      "Iteration 500, Loss: 0.2025\n",
      "Iteration 600, Loss: 0.1855\n",
      "Iteration 700, Loss: 0.1729\n",
      "Iteration 800, Loss: 0.1628\n",
      "Iteration 900, Loss: 0.1546\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 8: Evaluate custom model",
   "id": "6c7cb779de12e765"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:37.373308Z",
     "start_time": "2025-08-16T17:38:37.366695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred_custom = predict(X_test, w, b)\n",
    "metrics_custom = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_custom),\n",
    "    'Precision': precision_score(y_test, y_pred_custom),\n",
    "    'Recall': recall_score(y_test, y_pred_custom),\n",
    "    'F1-Score': f1_score(y_test, y_pred_custom)\n",
    "}"
   ],
   "id": "8d24144ae56dbd68",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 9: Compare with scikit-learn",
   "id": "fa5397055c75843e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:37.441726Z",
     "start_time": "2025-08-16T17:38:37.423858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sklearn_model = LogisticRegression(random_state=42)\n",
    "try:\n",
    "    sklearn_model.fit(X_train, y_train)\n",
    "except ValueError as e:\n",
    "    print(\"Error in scikit-learn fit:\", e)\n",
    "    raise\n",
    "y_pred_sklearn = sklearn_model.predict(X_test)\n",
    "metrics_sklearn = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_sklearn),\n",
    "    'Precision': precision_score(y_test, y_pred_sklearn),\n",
    "    'Recall': recall_score(y_test, y_pred_sklearn),\n",
    "    'F1-Score': f1_score(y_test, y_pred_sklearn)\n",
    "}"
   ],
   "id": "4a45d8b4758c34e3",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Print metrics",
   "id": "13206b6dcde32913"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:38:37.507691Z",
     "start_time": "2025-08-16T17:38:37.500948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nCustom Model Metrics:\")\n",
    "for metric, value in metrics_custom.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "print(\"\\nScikit-learn Model Metrics:\")\n",
    "for metric, value in metrics_sklearn.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ],
   "id": "dd2519cdd4c2da5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Model Metrics:\n",
      "Accuracy: 0.9474\n",
      "Precision: 0.8936\n",
      "Recall: 0.9767\n",
      "F1-Score: 0.9333\n",
      "\n",
      "Scikit-learn Model Metrics:\n",
      "Accuracy: 0.9737\n",
      "Precision: 0.9762\n",
      "Recall: 0.9535\n",
      "F1-Score: 0.9647\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
