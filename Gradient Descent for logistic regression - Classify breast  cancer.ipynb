{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries",
   "id": "5e741ae31fc2b3ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:27.999097Z",
     "start_time": "2025-08-16T16:06:23.434671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "be39a77a9166419b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: Load dataset",
   "id": "727968fad411fd7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.073070Z",
     "start_time": "2025-08-16T16:06:28.016829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    data = pd.read_csv('Breast cancer dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset file not found. Please ensure 'Breast cancer dataset.csv' is in the correct directory.\")\n",
    "    raise"
   ],
   "id": "80f7c16c2cabe01c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 3: Preprocess dataset\n",
    "# Identify numeric columns (excluding diagnosis for now)"
   ],
   "id": "d3c5764e37edf1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.122513Z",
     "start_time": "2025-08-16T16:06:28.086980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "print(\"Numeric columns:\", numeric_cols)"
   ],
   "id": "bff27d33f9d0c701",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: Index(['id', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
      "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check for missing values",
   "id": "a8415a6ac8f56c70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.262347Z",
     "start_time": "2025-08-16T16:06:28.138631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nChecking for missing values:\")\n",
    "print(data[numeric_cols].isna().sum())"
   ],
   "id": "9a8be390f223670c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values:\n",
      "id                         0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Impute missing values with median for numeric columns",
   "id": "c14572bbb3a66053"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.380472Z",
     "start_time": "2025-08-16T16:06:28.277362Z"
    }
   },
   "cell_type": "code",
   "source": "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())",
   "id": "3c9ecbe5856e548d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check for infinite values",
   "id": "673f67fb24b9be7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.419229Z",
     "start_time": "2025-08-16T16:06:28.392164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nChecking for infinite values:\")\n",
    "print(np.isinf(data[numeric_cols]).sum())\n",
    "data[numeric_cols] = data[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())"
   ],
   "id": "dcccc7112860a75f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for infinite values:\n",
      "id                         0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Verify no NaNs remain",
   "id": "2f256125203100e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.473716Z",
     "start_time": "2025-08-16T16:06:28.440185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nChecking for NaNs after imputation:\")\n",
    "print(data[numeric_cols].isna().sum())"
   ],
   "id": "c97252037f412e00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for NaNs after imputation:\n",
      "id                         0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Encode diagnosis",
   "id": "3f4288d8e95d1d4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.517950Z",
     "start_time": "2025-08-16T16:06:28.510595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'diagnosis' in data.columns:\n",
    "    data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "else:\n",
    "    print(\"Error: 'diagnosis' column not found.\")\n",
    "    raise KeyError(\"'diagnosis' column missing\")"
   ],
   "id": "96794cb513e553a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Drop id column if present"
   ],
   "id": "e25862ce04d98516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.535733Z",
     "start_time": "2025-08-16T16:06:28.530352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'id' in data.columns:\n",
    "    data = data.drop('id', axis=1)"
   ],
   "id": "def907d133639850",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Drop zero-variance features",
   "id": "893ac179b698d381"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.558326Z",
     "start_time": "2025-08-16T16:06:28.546125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zero_variance_cols = [col for col in numeric_cols if col in data.columns and data[col].var() == 0]\n",
    "print(\"\\nZero variance columns:\", zero_variance_cols)\n",
    "data = data.drop(columns=zero_variance_cols)"
   ],
   "id": "6b091a29b866bf7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zero variance columns: []\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Separate features and target",
   "id": "97d580c143b58ddc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T16:06:28.610621Z",
     "start_time": "2025-08-16T16:06:28.604939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data.drop('diagnosis', axis=1).values\n",
    "y = data['diagnosis'].values"
   ],
   "id": "c9ca6c6560d88c2c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Verify no NaNs in X",
   "id": "c1f811dd890a1d75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if np.any(np.isnan(X)):\n",
    "    print(\"Error: NaN values found in features after preprocessing.\")\n",
    "    raise ValueError(\"NaN values in X\")"
   ],
   "id": "7436d474635d11a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Standardize features",
   "id": "675b794fa96adad7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scaler = StandardScaler()\n",
    "try:\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "except ValueError as e:\n",
    "    print(\"Error in standardization:\", e)\n",
    "    raise"
   ],
   "id": "ee7b83486cb85f0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Split data",
   "id": "e59003e103e9e83c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)",
   "id": "d5b0d09f138a5498"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 4 & 6: Define and implement logistic regression from scratch",
   "id": "bef66531754097ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_loss(X, y, w, b):\n",
    "    m = len(y)\n",
    "    z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    epsilon = 1e-15\n",
    "    loss = -np.mean(y * np.log(y_hat + epsilon) + (1 - y) * np.log(1 - y_hat + epsilon))\n",
    "    return loss\n",
    "\n",
    "def gradient_descent(X, y, w, b, learning_rate, num_iterations):\n",
    "    m = len(y)\n",
    "    loss_history = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(X, w) + b\n",
    "        y_hat = sigmoid(z)\n",
    "        dw = np.dot(X.T, (y_hat - y)) / m\n",
    "        db = np.mean(y_hat - y)\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "        loss = compute_loss(X, y, w, b)\n",
    "        loss_history.append(loss)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return w, b, loss_history\n",
    "\n",
    "def predict(X, w, b, threshold=0.5):\n",
    "    z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    return (y_hat >= threshold).astype(int)\n"
   ],
   "id": "57a97ab3f6475e60"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train custom model",
   "id": "7182b75e0d6bc4c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bdb4240264e774cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
